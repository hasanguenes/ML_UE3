{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f98f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gtsrb_loader.py\n",
    "# DL-ready GTSRB Dataset + DataLoader (on-the-fly loading, with resizing via transforms)\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class GTSRBDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Expects this structure:\n",
    "\n",
    "    root/\n",
    "      Final_Training_Images/\n",
    "        00000/*.ppm\n",
    "        ...\n",
    "      Final_Test_Images/\n",
    "        *.ppm\n",
    "        GT-final_test.csv   (must contain Filename and ClassId)\n",
    "\n",
    "    Returns: (img_tensor, label_tensor)\n",
    "    - img_tensor: float32 (3,H,W) in [0,1] (and optionally normalized if you add Normalize in transforms)\n",
    "    - label_tensor: int64\n",
    "    \"\"\"\n",
    "    def __init__(self, root: str, split: str = \"train\", transform=None):\n",
    "        self.root = Path(root)\n",
    "        self.split = split.lower().strip()\n",
    "        self.transform = transform\n",
    "\n",
    "        if self.split == \"train\":\n",
    "            base = self.root / \"Final_Training_Images\"\n",
    "            if not base.exists():\n",
    "                raise FileNotFoundError(base)\n",
    "\n",
    "            paths, labels = [], []\n",
    "            for class_dir in sorted([d for d in base.iterdir() if d.is_dir()]):\n",
    "                y = int(class_dir.name)  # robust label\n",
    "                for p in sorted(class_dir.glob(\"*.ppm\")):\n",
    "                    paths.append(p)\n",
    "                    labels.append(y)\n",
    "\n",
    "            self.paths = paths\n",
    "            self.labels = np.asarray(labels, dtype=np.int64)\n",
    "\n",
    "        elif self.split == \"test\":\n",
    "            base = self.root / \"Final_Test_Images\"\n",
    "            csv_path = base / \"GT-final_test.csv\"\n",
    "            if not base.exists():\n",
    "                raise FileNotFoundError(base)\n",
    "            if not csv_path.exists():\n",
    "                raise FileNotFoundError(csv_path)\n",
    "\n",
    "            df = pd.read_csv(csv_path, sep=None, engine=\"python\")\n",
    "            df.columns = [c.strip() for c in df.columns]\n",
    "            if \"Filename\" not in df.columns or \"ClassId\" not in df.columns:\n",
    "                raise ValueError(f\"Need Filename and ClassId, got {df.columns.tolist()}\")\n",
    "\n",
    "            self.paths = [base / fn for fn in df[\"Filename\"].astype(str).tolist()]\n",
    "            self.labels = df[\"ClassId\"].astype(int).to_numpy(dtype=np.int64)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"split must be 'train' or 'test'\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        p = self.paths[idx]\n",
    "        y = int(self.labels[idx])\n",
    "\n",
    "        with Image.open(p) as im:\n",
    "            im = im.convert(\"RGB\")\n",
    "            if self.transform is not None:\n",
    "                x = self.transform(im)\n",
    "            else:\n",
    "                # default: tensor in [0,1], shape (3,H,W) without resizing\n",
    "                x = torch.from_numpy(np.array(im)).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "        return x, torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "\n",
    "def get_gtsrb_dataloaders(\n",
    "    root: str,\n",
    "    img_size=(32, 32),\n",
    "    batch_size: int = 128,\n",
    "    num_workers: int = 0,          # Windows default: 0 is often fastest\n",
    "    normalize: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns (train_loader, test_loader) for GTSRB.\n",
    "    Resizing is done via transforms.Resize(img_size).\n",
    "    \"\"\"\n",
    "    tfms = [transforms.Resize(img_size), transforms.ToTensor()]  # -> float in [0,1]\n",
    "\n",
    "    if normalize:\n",
    "        # Placeholder normalization. If you do transfer learning, use ImageNet stats.\n",
    "        # For training from scratch, you can compute dataset mean/std later.\n",
    "        mean = (0.5, 0.5, 0.5)\n",
    "        std  = (0.5, 0.5, 0.5)\n",
    "        tfms.append(transforms.Normalize(mean, std))\n",
    "\n",
    "    train_tfm = transforms.Compose(tfms)\n",
    "    test_tfm  = transforms.Compose(tfms)\n",
    "\n",
    "    train_ds = GTSRBDataset(root=root, split=\"train\", transform=train_tfm)\n",
    "    test_ds  = GTSRBDataset(root=root, split=\"test\",  transform=test_tfm)\n",
    "\n",
    "    pin = torch.cuda.is_available()\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=num_workers, pin_memory=pin\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_ds, batch_size=batch_size * 2, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=pin\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae64ead7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: torch.Size([128, 3, 64, 64]) torch.Size([128]) 0.0 1.0\n",
      "TEST : torch.Size([256, 3, 64, 64]) torch.Size([256]) 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = get_gtsrb_dataloaders(\n",
    "    root=\"./data/GTSRB\",\n",
    "    img_size=(64, 64),\n",
    "    batch_size=128,\n",
    "    num_workers=0,\n",
    "    normalize=False,\n",
    ")\n",
    "\n",
    "x, y = next(iter(train_loader))\n",
    "print(\"TRAIN:\", x.shape, y.shape, float(x.min()), float(x.max()))\n",
    "\n",
    "x2, y2 = next(iter(test_loader))\n",
    "print(\"TEST :\", x2.shape, y2.shape, float(x2.min()), float(x2.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea99d0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train images: 39209\n",
      "Loaded test images : 12630\n"
     ]
    }
   ],
   "source": [
    "# load_all_gtsrb.py\n",
    "# Loads ALL GTSRB images (train + test) through your DL loaders, so you can see the runtime.\n",
    "\n",
    "import torch\n",
    "\n",
    "# assumes you have get_gtsrb_dataloaders available (from the gtsrb_loader.py I gave you)\n",
    "# from gtsrb_loader import get_gtsrb_dataloaders\n",
    "\n",
    "def load_all_gtsrb(root=\"./data/GTSRB\", img_size=(64, 64), batch_size=256, num_workers=0):\n",
    "    train_loader, test_loader = get_gtsrb_dataloaders(\n",
    "        root=root,\n",
    "        img_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        normalize=False,\n",
    "    )\n",
    "\n",
    "    n_train = 0\n",
    "    for xb, yb in train_loader:\n",
    "        # xb: (B,3,H,W) float in [0,1]  | yb: (B,)\n",
    "        n_train += xb.size(0)\n",
    "    print(\"Loaded train images:\", n_train)\n",
    "\n",
    "    n_test = 0\n",
    "    for xb, yb in test_loader:\n",
    "        n_test += xb.size(0)\n",
    "    print(\"Loaded test images :\", n_test)\n",
    "\n",
    "\n",
    "load_all_gtsrb(\n",
    "    root=\"./data/GTSRB\",   # adjust if needed\n",
    "    img_size=(64, 64),     # try (32,32), (64,64), (224,224)\n",
    "    batch_size=256,\n",
    "    num_workers=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5faac821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "# assumes you have get_gtsrb_dataloaders available\n",
    "# from gtsrb_loader import get_gtsrb_dataloaders\n",
    "\n",
    "def _cache_split(loader, out_x: Path, out_y: Path):\n",
    "    xs, ys = [], []\n",
    "    for xb, yb in loader:\n",
    "        xs.append(xb.cpu())\n",
    "        ys.append(yb.cpu())\n",
    "    X = torch.cat(xs, dim=0)\n",
    "    y = torch.cat(ys, dim=0)\n",
    "    torch.save(X, out_x)\n",
    "    torch.save(y, out_y)\n",
    "    return X.shape[0]\n",
    "\n",
    "def build_gtsrb_cache(\n",
    "    root: str = \"./data/GTSRB\",\n",
    "    img_size=(32, 32),\n",
    "    batch_size: int = 256,\n",
    "    num_workers: int = 0,\n",
    "    cache_root: str = \"./cache_gtsrb\",\n",
    "):\n",
    "    # variant-specific folder name\n",
    "    variant_name = f\"{img_size[0]}x{img_size[1]}\"\n",
    "    cache_dir = Path(cache_root) / f\"gtsrb_{variant_name}\"\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_loader, test_loader = get_gtsrb_dataloaders(\n",
    "        root=root,\n",
    "        img_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        normalize=False,   # cache WITHOUT normalization\n",
    "    )\n",
    "\n",
    "    n_train = _cache_split(train_loader, cache_dir / \"X_train.pt\", cache_dir / \"y_train.pt\")\n",
    "    n_test  = _cache_split(test_loader,  cache_dir / \"X_test.pt\",  cache_dir / \"y_test.pt\")\n",
    "\n",
    "    meta = {\n",
    "        \"dataset\": \"GTSRB\",\n",
    "        \"root\": str(root),\n",
    "        \"img_size\": tuple(img_size),\n",
    "        \"cached_normalized\": False,\n",
    "        \"dtype\": \"float32 in [0,1]\",\n",
    "        \"n_train\": int(n_train),\n",
    "        \"n_test\": int(n_test),\n",
    "        \"created_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    }\n",
    "    torch.save(meta, cache_dir / \"meta.pt\")\n",
    "\n",
    "    print(f\"Saved cache to: {cache_dir}\")\n",
    "    print(f\"Meta: {meta}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e2da38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cache to: cache_gtsrb\\gtsrb_32x32\n",
      "Meta: {'dataset': 'GTSRB', 'root': './data/GTSRB', 'img_size': (32, 32), 'cached_normalized': False, 'dtype': 'float32 in [0,1]', 'n_train': 39209, 'n_test': 12630, 'created_at': '2026-01-24T13:26:53'}\n"
     ]
    }
   ],
   "source": [
    "build_gtsrb_cache(img_size=(32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d72d882d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cache to: cache_gtsrb\\gtsrb_64x64\n",
      "Meta: {'dataset': 'GTSRB', 'root': './data/GTSRB', 'img_size': (64, 64), 'cached_normalized': False, 'dtype': 'float32 in [0,1]', 'n_train': 39209, 'n_test': 12630, 'created_at': '2026-01-24T13:27:25'}\n"
     ]
    }
   ],
   "source": [
    "build_gtsrb_cache(img_size=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d89ab6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 1927202345\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "p = Path(\"./cache_gtsrb/gtsrb_64x64/X_train.pt\")\n",
    "print(p.exists(), p.stat().st_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
