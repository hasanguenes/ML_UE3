{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cac965c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits shape: torch.Size([8, 43])\n",
      "loss: 3.772609233856201\n",
      "backward ok, example grad mean: 0.0027019288390874863\n",
      "trainable parameters: 64811\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from DL_approach.LeNet import LeNet5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Beispiel: GTSRB mit 43 Klassen, aber 32x32 (weil du strict LeNet willst)\n",
    "model = LeNet5(in_channels=3, num_classes=43, input_size=32, activation=\"tanh\", adapt_to_lenet_geometry=False).to(device)\n",
    "\n",
    "# Dummy-Batch: batch_size=8, 3 Kanäle, 32x32\n",
    "x = torch.randn(8, 3, 32, 32, device=device)\n",
    "\n",
    "# Forward\n",
    "logits = model(x)\n",
    "print(\"logits shape:\", logits.shape)   # erwartet: torch.Size([8, 43])\n",
    "\n",
    "# Loss + Backward (prüft, ob Gradientenfluss ok ist)\n",
    "y = torch.randint(0, 43, (8,), device=device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(logits, y)\n",
    "loss.backward()\n",
    "\n",
    "print(\"loss:\", float(loss))\n",
    "print(\"backward ok, example grad mean:\",\n",
    "      model.c1.weight.grad.abs().mean().item())\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"trainable parameters:\", n_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b78940f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Train samples: 39209\n",
      "Test  samples: 12630\n",
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 70\u001b[39m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDone.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Train (uses testloader as eval loader here, matching your preferred workflow)\u001b[39;00m\n\u001b[32m     50\u001b[39m run_tag = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGTSRB32_dbg\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdebug_fraction\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_LeNet5_tanh_adam1e-3_do0.2\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m model, history = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevalloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_curves\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcurves_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtraining_curves\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_tag\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_tag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# Final eval (optional explicit call)\u001b[39;00m\n\u001b[32m     65\u001b[39m model.eval()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Repos\\ML_UE3\\ML_UE3\\DL_approach\\train_utils.py:217\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, trainloader, evalloader, optimizer, criterion, device, epochs, save_curves, curves_dir, curves_dpi, run_tag)\u001b[39m\n\u001b[32m    214\u001b[39m     torch.cuda.synchronize()\n\u001b[32m    215\u001b[39m t0 = time.perf_counter()\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m train_loss, train_acc = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device.type == \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    226\u001b[39m     torch.cuda.synchronize()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Repos\\ML_UE3\\ML_UE3\\DL_approach\\train_utils.py:86\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, dataloader, optimizer, criterion, device)\u001b[39m\n\u001b[32m     83\u001b[39m num_samples: \u001b[38;5;28mint\u001b[39m = \u001b[32m0\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# leave=False avoids cluttering the console with many progress bars across epochs\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTraining\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleave\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_move_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Zero gradients from the previous step.\u001b[39;49;00m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# set_to_none=True is a performance/memory optimization recommended by PyTorch in many cases.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guene\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guene\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guene\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guene\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Repos\\ML_UE3\\ML_UE3\\data\\gtsrb_loader.py:138\u001b[39m, in \u001b[36mGTSRBDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    135\u001b[39m p = \u001b[38;5;28mself\u001b[39m.paths[idx]\n\u001b[32m    136\u001b[39m y = \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m.labels[idx])\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m im:\n\u001b[32m    139\u001b[39m     im = im.convert(\u001b[33m\"\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    140\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guene\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\PIL\\Image.py:3505\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3502\u001b[39m     filename = os.fspath(fp)\n\u001b[32m   3504\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[32m-> \u001b[39m\u001b[32m3505\u001b[39m     fp = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3506\u001b[39m     exclusive_fp = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# quick_train_lenet_gtsrb_debug.py\n",
    "# Minimal debug run: load only a fraction of GTSRB and train LeNet for a few epochs.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from data.gtsrb_loader import get_gtsrb_dataloaders\n",
    "from DL_approach.train_utils import train_model\n",
    "from DL_approach.LeNet import LeNet5  # adjust import to your file name\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Device:\", device)\n",
    "\n",
    "    # Debug fraction: e.g., 5% of train + 5% of test\n",
    "    debug_fraction = 1 # 0.05\n",
    "\n",
    "    # Data\n",
    "    trainloader, testloader = get_gtsrb_dataloaders(\n",
    "        root=\"data/GTSRB\",\n",
    "        img_size=(32, 32),          # strict classic LeNet geometry\n",
    "        batch_size=128,\n",
    "        num_workers=0,\n",
    "        normalize=True,\n",
    "        debug_fraction=debug_fraction,\n",
    "        seed=42,\n",
    "    )\n",
    "\n",
    "    print(\"Train samples:\", len(trainloader.dataset))\n",
    "    print(\"Test  samples:\", len(testloader.dataset))\n",
    "\n",
    "    # Model\n",
    "    model = LeNet5(\n",
    "        in_channels=3,\n",
    "        num_classes=43,\n",
    "        input_size=32,\n",
    "        activation=\"tanh\",\n",
    "        adapt_to_lenet_geometry=False,\n",
    "        dropout_p=0.2,              # set 0.0 to disable\n",
    "    ).to(device)\n",
    "\n",
    "    # Training setup\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # Train (uses testloader as eval loader here, matching your preferred workflow)\n",
    "    run_tag = f\"GTSRB32_dbg{debug_fraction}_LeNet5_tanh_adam1e-3_do0.2\"\n",
    "    model, history = train_model(\n",
    "        model=model,\n",
    "        trainloader=trainloader,\n",
    "        evalloader=testloader,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        epochs=3,\n",
    "        save_curves=True,\n",
    "        curves_dir=\"training_curves\",\n",
    "        run_tag=run_tag,\n",
    "    )\n",
    "\n",
    "    # Final eval (optional explicit call)\n",
    "    model.eval()\n",
    "    print(\"\\nDone.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5da8e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Train samples: 39209\n",
      "Test  samples: 12630\n",
      "\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6276 | Train Acc: 0.5649 | Time: 21.09s\n",
      "Eval  Loss: 0.7348 | Eval  Acc: 0.8055 | Time: 7.50s\n",
      "\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3810 | Train Acc: 0.9091 | Time: 27.51s\n",
      "Eval  Loss: 0.4342 | Eval  Acc: 0.8841 | Time: 5.94s\n",
      "\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1943 | Train Acc: 0.9557 | Time: 30.91s\n",
      "Eval  Loss: 0.3788 | Eval  Acc: 0.9000 | Time: 6.81s\n",
      "\n",
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1251 | Train Acc: 0.9723 | Time: 23.40s\n",
      "Eval  Loss: 0.3417 | Eval  Acc: 0.9116 | Time: 4.61s\n",
      "\n",
      "Epoch 5/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0897 | Train Acc: 0.9807 | Time: 21.00s\n",
      "Eval  Loss: 0.3328 | Eval  Acc: 0.9135 | Time: 5.65s\n",
      "\n",
      "Epoch 6/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0674 | Train Acc: 0.9858 | Time: 25.99s\n",
      "Eval  Loss: 0.3288 | Eval  Acc: 0.9135 | Time: 6.69s\n",
      "\n",
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0495 | Train Acc: 0.9896 | Time: 27.64s\n",
      "Eval  Loss: 0.3273 | Eval  Acc: 0.9197 | Time: 5.18s\n",
      "\n",
      "Epoch 8/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0386 | Train Acc: 0.9924 | Time: 17.15s\n",
      "Eval  Loss: 0.3373 | Eval  Acc: 0.9187 | Time: 5.11s\n",
      "\n",
      "Epoch 9/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0325 | Train Acc: 0.9932 | Time: 16.96s\n",
      "Eval  Loss: 0.3201 | Eval  Acc: 0.9219 | Time: 4.92s\n",
      "\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0249 | Train Acc: 0.9952 | Time: 28.10s\n",
      "Eval  Loss: 0.3288 | Eval  Acc: 0.9212 | Time: 6.76s\n",
      "\n",
      "Epoch 11/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0189 | Train Acc: 0.9966 | Time: 18.26s\n",
      "Eval  Loss: 0.3232 | Eval  Acc: 0.9233 | Time: 6.25s\n",
      "\n",
      "Epoch 12/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0171 | Train Acc: 0.9967 | Time: 28.98s\n",
      "Eval  Loss: 0.3266 | Eval  Acc: 0.9255 | Time: 4.47s\n",
      "\n",
      "Epoch 13/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0135 | Train Acc: 0.9976 | Time: 24.80s\n",
      "Eval  Loss: 0.3546 | Eval  Acc: 0.9188 | Time: 5.64s\n",
      "\n",
      "Epoch 14/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0128 | Train Acc: 0.9976 | Time: 26.44s\n",
      "Eval  Loss: 0.3159 | Eval  Acc: 0.9257 | Time: 7.71s\n",
      "\n",
      "Epoch 15/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0129 | Train Acc: 0.9971 | Time: 20.26s\n",
      "Eval  Loss: 0.3252 | Eval  Acc: 0.9222 | Time: 8.28s\n",
      "\n",
      "Epoch 16/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0135 | Train Acc: 0.9969 | Time: 27.37s\n",
      "Eval  Loss: 0.3568 | Eval  Acc: 0.9179 | Time: 8.28s\n",
      "\n",
      "Epoch 17/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0110 | Train Acc: 0.9976 | Time: 23.79s\n",
      "Eval  Loss: 0.3644 | Eval  Acc: 0.9140 | Time: 5.71s\n",
      "\n",
      "Epoch 18/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0067 | Train Acc: 0.9989 | Time: 19.03s\n",
      "Eval  Loss: 0.3310 | Eval  Acc: 0.9314 | Time: 5.77s\n",
      "\n",
      "Epoch 19/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0045 | Train Acc: 0.9992 | Time: 19.14s\n",
      "Eval  Loss: 0.3650 | Eval  Acc: 0.9218 | Time: 6.27s\n",
      "\n",
      "Epoch 20/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0060 | Train Acc: 0.9990 | Time: 22.21s\n",
      "Eval  Loss: 0.3520 | Eval  Acc: 0.9291 | Time: 5.94s\n",
      "\n",
      "Epoch 21/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0092 | Train Acc: 0.9977 | Time: 20.18s\n",
      "Eval  Loss: 0.3973 | Eval  Acc: 0.9211 | Time: 6.84s\n",
      "\n",
      "Epoch 22/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0103 | Train Acc: 0.9973 | Time: 19.05s\n",
      "Eval  Loss: 0.3828 | Eval  Acc: 0.9243 | Time: 5.72s\n",
      "\n",
      "Epoch 23/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0094 | Train Acc: 0.9975 | Time: 26.34s\n",
      "Eval  Loss: 0.3658 | Eval  Acc: 0.9250 | Time: 6.40s\n",
      "\n",
      "Epoch 24/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0088 | Train Acc: 0.9979 | Time: 23.42s\n",
      "Eval  Loss: 0.3884 | Eval  Acc: 0.9252 | Time: 7.03s\n",
      "\n",
      "Epoch 25/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0032 | Train Acc: 0.9995 | Time: 22.93s\n",
      "Eval  Loss: 0.3696 | Eval  Acc: 0.9272 | Time: 5.03s\n",
      "\n",
      "Runtime summary:\n",
      "  total train time: 581.95s\n",
      "  total eval  time: 154.50s\n",
      "Saved training curves to: training_curves\\LeNet5_GTSRB32_dbg1_LeNet5_tanh_adam1e-3_do0_2_20260125-070340_curves.png\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# quick_train_lenet_gtsrb_debug.py\n",
    "# Minimal debug run: load only a fraction of GTSRB and train LeNet for a few epochs.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from data.cifar_loader import CIFAR10\n",
    "from DL_approach.train_utils import train_model\n",
    "from DL_approach.LeNet import LeNet5  # adjust import to your file name\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Device:\", device)\n",
    "\n",
    "    # Debug fraction: e.g., 5% of train + 5% of test\n",
    "    debug_fraction = 1 # 0.05\n",
    "\n",
    "    # Data\n",
    "    trainloader, testloader = get_gtsrb_dataloaders(\n",
    "        root=\"data/GTSRB\",\n",
    "        img_size=(32, 32),          # strict classic LeNet geometry\n",
    "        batch_size=128,\n",
    "        num_workers=0,\n",
    "        normalize=True,\n",
    "        debug_fraction=debug_fraction,\n",
    "        seed=42,\n",
    "    )\n",
    "\n",
    "    print(\"Train samples:\", len(trainloader.dataset))\n",
    "    print(\"Test  samples:\", len(testloader.dataset))\n",
    "\n",
    "    # Model\n",
    "    model = LeNet5(\n",
    "        in_channels=3,\n",
    "        num_classes=43,\n",
    "        input_size=32,\n",
    "        activation=\"tanh\",\n",
    "        adapt_to_lenet_geometry=False,\n",
    "        dropout_p=0.2,              # set 0.0 to disable\n",
    "    ).to(device)\n",
    "\n",
    "    # Training setup\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # Train (uses testloader as eval loader here, matching your preferred workflow)\n",
    "    run_tag = f\"GTSRB32_dbg{debug_fraction}_LeNet5_tanh_adam1e-3_do0.2\"\n",
    "    model, history = train_model(\n",
    "        model=model,\n",
    "        trainloader=trainloader,\n",
    "        evalloader=testloader,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        epochs=25,\n",
    "        save_curves=True,\n",
    "        curves_dir=\"training_curves\",\n",
    "        run_tag=run_tag,\n",
    "    )\n",
    "\n",
    "    # Final eval (optional explicit call)\n",
    "    model.eval()\n",
    "    print(\"\\nDone.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26024a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Train samples: 50000\n",
      "Test  samples: 10000\n",
      "\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.7972 | Train Acc: 0.3587 | Time: 4.57s\n",
      "Eval  Loss: 1.6284 | Eval  Acc: 0.4244 | Time: 0.44s\n",
      "\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5444 | Train Acc: 0.4488 | Time: 3.95s\n",
      "Eval  Loss: 1.4457 | Eval  Acc: 0.4855 | Time: 0.50s\n",
      "\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3990 | Train Acc: 0.5003 | Time: 3.62s\n",
      "Eval  Loss: 1.3606 | Eval  Acc: 0.5159 | Time: 0.56s\n",
      "\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3165 | Train Acc: 0.5295 | Time: 7.13s\n",
      "Eval  Loss: 1.2969 | Eval  Acc: 0.5346 | Time: 0.99s\n",
      "\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2543 | Train Acc: 0.5522 | Time: 6.25s\n",
      "Eval  Loss: 1.2882 | Eval  Acc: 0.5366 | Time: 1.12s\n",
      "\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2102 | Train Acc: 0.5699 | Time: 7.36s\n",
      "Eval  Loss: 1.2606 | Eval  Acc: 0.5476 | Time: 1.06s\n",
      "\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1746 | Train Acc: 0.5820 | Time: 7.17s\n",
      "Eval  Loss: 1.2592 | Eval  Acc: 0.5521 | Time: 0.98s\n",
      "\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1438 | Train Acc: 0.5925 | Time: 7.36s\n",
      "Eval  Loss: 1.2396 | Eval  Acc: 0.5566 | Time: 1.20s\n",
      "\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1101 | Train Acc: 0.6024 | Time: 7.26s\n",
      "Eval  Loss: 1.2435 | Eval  Acc: 0.5566 | Time: 0.51s\n",
      "\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0919 | Train Acc: 0.6107 | Time: 3.89s\n",
      "Eval  Loss: 1.2401 | Eval  Acc: 0.5589 | Time: 0.44s\n",
      "\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0621 | Train Acc: 0.6235 | Time: 3.75s\n",
      "Eval  Loss: 1.2519 | Eval  Acc: 0.5565 | Time: 0.44s\n",
      "\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0403 | Train Acc: 0.6295 | Time: 3.78s\n",
      "Eval  Loss: 1.2165 | Eval  Acc: 0.5735 | Time: 0.45s\n",
      "\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0208 | Train Acc: 0.6364 | Time: 4.13s\n",
      "Eval  Loss: 1.2377 | Eval  Acc: 0.5655 | Time: 0.49s\n",
      "\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9979 | Train Acc: 0.6452 | Time: 3.99s\n",
      "Eval  Loss: 1.2308 | Eval  Acc: 0.5646 | Time: 0.49s\n",
      "\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9828 | Train Acc: 0.6503 | Time: 4.30s\n",
      "Eval  Loss: 1.2338 | Eval  Acc: 0.5712 | Time: 0.45s\n",
      "\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9638 | Train Acc: 0.6572 | Time: 3.98s\n",
      "Eval  Loss: 1.2569 | Eval  Acc: 0.5634 | Time: 0.48s\n",
      "\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9449 | Train Acc: 0.6648 | Time: 4.41s\n",
      "Eval  Loss: 1.2635 | Eval  Acc: 0.5628 | Time: 0.48s\n",
      "\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9288 | Train Acc: 0.6711 | Time: 3.93s\n",
      "Eval  Loss: 1.2675 | Eval  Acc: 0.5656 | Time: 0.49s\n",
      "\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9142 | Train Acc: 0.6763 | Time: 3.99s\n",
      "Eval  Loss: 1.2679 | Eval  Acc: 0.5681 | Time: 0.52s\n",
      "\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9018 | Train Acc: 0.6800 | Time: 4.01s\n",
      "Eval  Loss: 1.2693 | Eval  Acc: 0.5702 | Time: 0.48s\n",
      "\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8816 | Train Acc: 0.6874 | Time: 4.23s\n",
      "Eval  Loss: 1.2881 | Eval  Acc: 0.5655 | Time: 0.49s\n",
      "\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8681 | Train Acc: 0.6944 | Time: 4.09s\n",
      "Eval  Loss: 1.2831 | Eval  Acc: 0.5687 | Time: 0.52s\n",
      "\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8553 | Train Acc: 0.6998 | Time: 4.37s\n",
      "Eval  Loss: 1.2925 | Eval  Acc: 0.5641 | Time: 0.57s\n",
      "\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8416 | Train Acc: 0.7039 | Time: 7.19s\n",
      "Eval  Loss: 1.3072 | Eval  Acc: 0.5642 | Time: 0.88s\n",
      "\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8285 | Train Acc: 0.7060 | Time: 4.41s\n",
      "Eval  Loss: 1.3242 | Eval  Acc: 0.5678 | Time: 0.64s\n",
      "\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8151 | Train Acc: 0.7132 | Time: 5.05s\n",
      "Eval  Loss: 1.3355 | Eval  Acc: 0.5614 | Time: 1.06s\n",
      "\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7991 | Train Acc: 0.7180 | Time: 5.19s\n",
      "Eval  Loss: 1.3416 | Eval  Acc: 0.5631 | Time: 0.53s\n",
      "\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7912 | Train Acc: 0.7218 | Time: 4.57s\n",
      "Eval  Loss: 1.3458 | Eval  Acc: 0.5626 | Time: 0.51s\n",
      "\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7771 | Train Acc: 0.7256 | Time: 4.40s\n",
      "Eval  Loss: 1.3920 | Eval  Acc: 0.5561 | Time: 0.54s\n",
      "\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7709 | Train Acc: 0.7285 | Time: 5.69s\n",
      "Eval  Loss: 1.3764 | Eval  Acc: 0.5606 | Time: 0.53s\n",
      "\n",
      "Runtime summary:\n",
      "  total train time: 148.02s\n",
      "  total eval  time: 18.84s\n",
      "Saved training curves to: training_curves\\LeNet5_CIFAR10_32_dbg_LeNet5_tanh_adam1e-3_do0_2_20260125-061400_curves.png\n",
      "One-batch test accuracy: 0.566\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# quick_train_lenet_cifar_debug.py\n",
    "# Minimal debug run: use YOUR existing CIFAR10 implementation + dataloader helper\n",
    "# and train LeNet for a few epochs.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# adjust these imports to your project structure\n",
    "from data.cifar_loader import get_cifar10_dataloaders   # <- this is the function you posted\n",
    "from DL_approach.train_utils import train_model\n",
    "from DL_approach.LeNet import LeNet5\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Device:\", device)\n",
    "\n",
    "    # Data\n",
    "    # - root must be the folder that contains \"cifar-10-batches-py/\"\n",
    "    #   e.g. root=\"data\" if you have data/cifar-10-batches-py/...\n",
    "    trainloader, testloader = get_cifar10_dataloaders(\n",
    "        root=\"data\",\n",
    "        batch_size=128,\n",
    "        num_workers=0, \n",
    "        normalize=True,\n",
    "        img_size=(32, 32),\n",
    "        train_transform=None,\n",
    "        test_transform=None,\n",
    "    )\n",
    "\n",
    "    print(\"Train samples:\", len(trainloader.dataset))\n",
    "    print(\"Test  samples:\", len(testloader.dataset))\n",
    "\n",
    "    # Model (CIFAR-10 -> 10 classes)\n",
    "    model = LeNet5(\n",
    "        in_channels=3,\n",
    "        num_classes=10,\n",
    "        input_size=32,\n",
    "        activation=\"tanh\",\n",
    "        adapt_to_lenet_geometry=False,\n",
    "        dropout_p=0.2,\n",
    "    ).to(device)\n",
    "\n",
    "    # Training setup\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # Train (using testloader as eval loader, same as your GTSRB debug script)\n",
    "    run_tag = \"CIFAR10_32_dbg_LeNet5_tanh_adam1e-3_do0.2\"\n",
    "    model, history = train_model(\n",
    "        model=model,\n",
    "        trainloader=trainloader,\n",
    "        evalloader=testloader,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        epochs=30,\n",
    "        save_curves=True,\n",
    "        curves_dir=\"training_curves\",\n",
    "        run_tag=run_tag,\n",
    "    )\n",
    "\n",
    "    # Quick sanity eval\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        xb, yb = next(iter(testloader))\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        logits = model(xb)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        acc = (preds == yb).float().mean().item()\n",
    "        print(f\"One-batch test accuracy: {acc:.3f}\")\n",
    "\n",
    "    print(\"\\nDone.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
